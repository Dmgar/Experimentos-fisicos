{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HQikA3HSdM0g"
      },
      "outputs": [],
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript, Image, HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "cVf2D4q6dQcA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# JavaScript y HTML para crear nuestro \"front\"\n",
        "def video_stream():\n",
        "  # 1. --- Definir el HTML y CSS de la interfaz ---\n",
        "  ui_html = HTML('''\n",
        "    <div style=\"font-family: sans-serif; padding: 10px; border: 1px solid #ccc; border-radius: 8px; width: 680px; margin: auto;\">\n",
        "        <h2 style=\"margin-top: 0;\"> Detector de Movimiento</h2>\n",
        "        <p>Haz clic en el video para detener la captura y guardar el CSV.</p>\n",
        "\n",
        "        <div id=\"video_container\" style=\"position: relative; width: 640px; height: 480px; margin: auto; border: 2px solid black;\">\n",
        "            <video id=\"video_element\" style=\"display: block; width: 100%; height: 100%;\" autoplay playsinline></video>\n",
        "            <img id=\"overlay_element\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1;\">\n",
        "        </div>\n",
        "\n",
        "        <div style=\"margin-top: 10px; font-size: 1.1em;\">\n",
        "            <strong>Estado:</strong> <span id=\"status_label\" style=\"font-weight: bold; color: #555;\">Iniciando...</span>\n",
        "        </div>\n",
        "\n",
        "        <div id=\"results_area\" style=\"margin-top: 20px; text-align: center;\">\n",
        "            <p>Esperando la finalización del video para generar el análisis...</p>\n",
        "        </div>\n",
        "    </div>\n",
        "  ''')\n",
        "  display(ui_html)\n",
        "\n",
        "  # 2. --- Definir el JavaScript (el \"puente\") ---\n",
        "  # El código JS es el mismo que en la respuesta anterior (sin cambios)\n",
        "  js_code = Javascript('''\n",
        "    var video;\n",
        "    var overlay;\n",
        "    var captureCanvas;\n",
        "    var labelElement;\n",
        "    var stream;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       if (stream) {\n",
        "           stream.getVideoTracks()[0].stop();\n",
        "       }\n",
        "       video = null;\n",
        "       overlay = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "       stream = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (video) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      // Encontrar los elementos que definimos en el HTML\n",
        "      video = document.getElementById('video_element');\n",
        "      overlay = document.getElementById('overlay_element');\n",
        "      labelElement = document.getElementById('status_label');\n",
        "\n",
        "      // Configurar el canvas oculto para la captura\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640;\n",
        "      captureCanvas.height = 480;\n",
        "\n",
        "      // Iniciar la cámara\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\" }});\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Configurar el clic para detener\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      overlay.onclick = () => { shutdown = true; };\n",
        "\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      return stream;\n",
        "    }\n",
        "\n",
        "    // Esta es la función que Python llama (el \"puente\")\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        overlay.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "  display(js_code)\n",
        "\n",
        "# Esta es la función de Python que llama al JS \"stream_frame\"\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\\\"{}\\\", \\\"{}\\\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "m2Pn87KUevtM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- IMPORTACIONES ADICIONALES NECESARIAS PARA LA VISUALIZACIÓN ---\n",
        "from scipy.signal import find_peaks\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML\n",
        "import io\n",
        "import base64\n",
        "import os\n",
        "from flask import Flask, render_template_string\n",
        "from threading import Thread\n",
        "import time as time_module\n",
        "\n",
        "# --- FUNCIÓN DE AYUDA PARA EXPORTAR GRÁFICAS A BASE64 ---\n",
        "def plot_to_base64(fig, title=\"\"):\n",
        "    \"\"\"Guarda una figura de Matplotlib en un string PNG base64 y la cierra.\"\"\"\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf, format='png', bbox_inches='tight', dpi=150)\n",
        "    plt.close(fig)\n",
        "    data = base64.b64encode(buf.getbuffer()).decode(\"ascii\")\n",
        "    html_img = f'<div class=\"graph-container\"><h4 class=\"graph-title\">{title}</h4><img src=\"data:image/png;base64,{data}\" class=\"graph-image expandable-image\"></div>'\n",
        "    return html_img\n",
        "\n",
        "# --- INICIALIZACIÓN DEL BUCLE DE VIDEO (COMO ANTES) ---\n",
        "video_stream()\n",
        "label_html = 'Capturando...'\n",
        "bbox = ''\n",
        "count = 0\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50, detectShadows=False)\n",
        "centroid_data = []\n",
        "start_time = time.time()\n",
        "processed_frames = []\n",
        "\n",
        "print(\"Iniciando stream... Haz clic en el video para detener y generar el análisis.\")\n",
        "\n",
        "# ----------------- BUCLE DE CAPTURA -----------------\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # Validar que js_reply tenga el formato correcto\n",
        "    try:\n",
        "        if \"img\" not in js_reply:\n",
        "            print(\"Error: 'img' no encontrado en js_reply\")\n",
        "            break\n",
        "\n",
        "        img = js_to_image(js_reply[\"img\"])\n",
        "        if img is None or img.size == 0:\n",
        "            print(\"Error: Imagen vacía o inválida\")\n",
        "            continue\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al procesar imagen: {e}\")\n",
        "        continue\n",
        "\n",
        "    current_time = time.time() - start_time\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "    display_img = img.copy()\n",
        "\n",
        "    fgmask = fgbg.apply(img)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
        "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_CLOSE, kernel)\n",
        "    cnts, _ = cv2.findContours(fgmask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    cx, cy = None, None\n",
        "    if cnts:\n",
        "        largest_contour = max(cnts, key=cv2.contourArea)\n",
        "        if cv2.contourArea(largest_contour) > 100:\n",
        "            M = cv2.moments(largest_contour)\n",
        "            if M[\"m00\"] != 0:\n",
        "                cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "                cv2.circle(bbox_array, (cx, cy), 10, (255, 0, 0, 255), -1)\n",
        "                cv2.drawContours(bbox_array, [largest_contour], -1, (0, 255, 0, 255), 2)\n",
        "                cv2.circle(display_img, (cx, cy), 10, (0, 0, 255), -1)\n",
        "                cv2.drawContours(display_img, [largest_contour], -1, (0, 255, 0), 2)\n",
        "\n",
        "    centroid_data.append([count, current_time, cx, cy])\n",
        "    processed_frames.append(display_img.copy())\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    bbox = bbox_bytes\n",
        "\n",
        "    label_html = f\"Procesando frame {count}...\"\n",
        "    count += 1\n",
        "\n",
        "print(f\"\\nStream detenido. Se procesaron {count} fotogramas.\")\n",
        "\n",
        "# --- 1. GUARDAR CSV Y PREPARAR ANÁLISIS ---\n",
        "csv_filename = 'centroid_data.csv'\n",
        "df = pd.DataFrame(centroid_data, columns=['frame_index', 'time_seconds', 'centroid_x', 'centroid_y'])\n",
        "df.to_csv(csv_filename, index=False)\n",
        "print(f\"Datos guardados exitosamente en '{csv_filename}'\")\n",
        "\n",
        "right_panel_content = ''\n",
        "video_and_coeff_content = ''\n",
        "coeff_section_html = ''\n",
        "\n",
        "df_filtered = df.dropna(subset=['centroid_x', 'centroid_y']).reset_index(drop=True)\n",
        "\n",
        "# ----------------- 2. GENERACIÓN DE GRÁFICAS Y TEXTO -----------------\n",
        "if not df_filtered.empty:\n",
        "    x_coords = df_filtered['centroid_x']\n",
        "    y_coords = df_filtered['centroid_y']\n",
        "    time_coords = df_filtered['time_seconds']\n",
        "\n",
        "    # A. Gráfico 1: Trayectoria X vs Y\n",
        "    fig1, ax1 = plt.subplots(figsize=(10, 7))\n",
        "    ax1.plot(x_coords, y_coords, marker='o', markersize=5, linestyle='-', linewidth=2, color='#1a73e8')\n",
        "    ax1.set_title(\"Trayectoria del centroide (X vs Y)\", fontsize=14, fontweight='500', pad=15)\n",
        "    ax1.set_xlabel(\"Coordenada X (píxeles)\", fontsize=12)\n",
        "    ax1.set_ylabel(\"Coordenada Y (píxeles)\", fontsize=12)\n",
        "    ax1.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)\n",
        "    ax1.invert_yaxis()\n",
        "    ax1.tick_params(labelsize=10)\n",
        "    plt.tight_layout()\n",
        "    right_panel_content += plot_to_base64(fig1, \"1. Trayectoria del Centroide\")\n",
        "\n",
        "    # B. Gráfico 2: Y vs Tiempo y Picos de Rebote\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 7))\n",
        "    ax2.plot(time_coords, y_coords, label=\"Trayectoria Y vs Tiempo\", color=\"#1a73e8\", linewidth=2)\n",
        "\n",
        "    inverted_disp_array = y_coords.values * -1\n",
        "    inverted_peaks, _ = find_peaks(inverted_disp_array, distance=10, prominence=5)\n",
        "\n",
        "    if len(inverted_peaks) > 0:\n",
        "        ax2.scatter(time_coords.values[inverted_peaks], y_coords.values[inverted_peaks],\n",
        "                   color=\"red\", s=80, zorder=3, label=\"Picos detectados (Rebotes)\", marker='^')\n",
        "\n",
        "    ax2.set_title(\"2. Coordenada Y en Función del Tiempo (con Rebotes)\", fontsize=14, fontweight='500', pad=15)\n",
        "    ax2.set_xlabel(\"Tiempo (s)\", fontsize=12)\n",
        "    ax2.set_ylabel(\"Coordenada Y (píxeles)\", fontsize=12)\n",
        "    ax2.legend(fontsize=11, loc='best', framealpha=0.9)\n",
        "    ax2.grid(True, alpha=0.3, linestyle='--', linewidth=0.8)\n",
        "    ax2.invert_yaxis()\n",
        "    ax2.tick_params(labelsize=10)\n",
        "    plt.tight_layout()\n",
        "    right_panel_content += plot_to_base64(fig2, \"2. Posición Y vs Tiempo\")\n",
        "\n",
        "    # C. Cálculo de Coeficiente de Restitución (e)\n",
        "    if len(inverted_peaks) > 1:\n",
        "        peaks_y = np.insert(y_coords.values[inverted_peaks], 0, y_coords.iloc[0])\n",
        "        y_floor = np.max(y_coords)\n",
        "        heights = np.array([y_floor - peak for peak in peaks_y])\n",
        "        h_drops = heights[:-1]\n",
        "        h_rebounds = heights[1:]\n",
        "        h_drops[h_drops <= 0] = 1e-6\n",
        "\n",
        "        restitution_coeffs = np.sqrt(h_rebounds / h_drops)\n",
        "        avg_coeff = restitution_coeffs.mean()\n",
        "\n",
        "        elasticity_classification = \"\"\n",
        "        if avg_coeff >= 0.95:\n",
        "            elasticity_classification = \"Elástico\"\n",
        "        elif avg_coeff <= 0.05:\n",
        "            elasticity_classification = \"Inelástico\"\n",
        "        else:\n",
        "            elasticity_classification = \"Parcialmente Elástico\"\n",
        "\n",
        "        coeff_list_formatted = ', '.join([f'{c:.4f}' for c in restitution_coeffs])\n",
        "\n",
        "        coeff_section_html = f'''\n",
        "        <div class=\"coefficient-section\">\n",
        "            <h4 class=\"coeff-title\">3. Coeficiente de Restitución (e)</h4>\n",
        "            <div class=\"coeff-item\">\n",
        "                <span class=\"coeff-label\">Rebotes detectados:</span>\n",
        "                <span class=\"coeff-value\">{len(restitution_coeffs)}</span>\n",
        "            </div>\n",
        "            <div class=\"coeff-item\">\n",
        "                <span class=\"coeff-label\">Coeficientes calculados (e):</span>\n",
        "                <span class=\"coeff-value-list\">{coeff_list_formatted}</span>\n",
        "            </div>\n",
        "            <div class=\"coeff-item-highlight\">\n",
        "                <span class=\"coeff-label\">Coeficiente de restitución promedio:</span>\n",
        "                <span class=\"coeff-value-highlight\">{avg_coeff:.4f}</span>\n",
        "            </div>\n",
        "            <div class=\"coeff-item\">\n",
        "                <span class=\"coeff-label\">Clasificación del objeto:</span>\n",
        "                <span class=\"coeff-classification\">{elasticity_classification}</span>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"info-section\">\n",
        "            <h4 class=\"info-title\"> ¿Qué es el Coeficiente de Restitución?</h4>\n",
        "            <p class=\"info-text\">\n",
        "                El coeficiente de restitución (e) mide la <strong>elasticidad de un objeto</strong> al rebotar.\n",
        "                Compara la altura alcanzada después del rebote con la altura de caída inicial.\n",
        "            </p>\n",
        "            <ul class=\"info-list\">\n",
        "                <li><strong>e ≈ 1.0 (Elástico):</strong> El objeto recupera casi toda su energía. Ejemplo: pelota de golf, superball.</li>\n",
        "                <li><strong>e ≈ 0.5 (Parcialmente Elástico):</strong> El objeto pierde energía moderada. Ejemplo: pelota de tenis, baloncesto.</li>\n",
        "                <li><strong>e ≈ 0.0 (Inelástico):</strong> El objeto no rebota, absorbiendo toda la energía. Ejemplo: masa de plastilina.</li>\n",
        "            </ul>\n",
        "            <p class=\"info-text\">\n",
        "                <strong>Aplicaciones:</strong> Diseño de equipos deportivos, análisis de colisiones vehiculares,\n",
        "                ingeniería de materiales y control de calidad en manufactura.\n",
        "            </p>\n",
        "        </div>\n",
        "        '''\n",
        "    else:\n",
        "        coeff_section_html = '<div class=\"error-message\">No se detectaron suficientes rebotes (mínimo 2) para calcular el coeficiente de restitución (e) y clasificar el objeto.</div>'\n",
        "else:\n",
        "    right_panel_content += '<div class=\"error-message\">No se detectó ningún movimiento válido para generar las gráficas.</div>'\n",
        "    coeff_section_html = '<div class=\"error-message\">No se detectó ningún movimiento válido para calcular el coeficiente.</div>'\n",
        "\n",
        "# --- GENERAR EL VIDEO A PARTIR DE LOS FOTOGRAMAS PROCESADOS ---\n",
        "video_filename = 'motion_detection_video.mp4'\n",
        "\n",
        "if processed_frames:\n",
        "    height, width, _ = processed_frames[0].shape\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    fps = 10\n",
        "\n",
        "    if os.path.exists(video_filename):\n",
        "        os.remove(video_filename)\n",
        "        print(f\"Archivo '{video_filename}' existente eliminado.\")\n",
        "\n",
        "    out = cv2.VideoWriter(video_filename, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame in processed_frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    print(f\"Video '{video_filename}' generado exitosamente con {len(processed_frames)} fotogramas.\")\n",
        "\n",
        "    with open(video_filename, 'rb') as f:\n",
        "        video_bytes = f.read()\n",
        "    video_base64 = base64.b64encode(video_bytes).decode('ascii')\n",
        "\n",
        "    try:\n",
        "        with open('logo.png', 'rb') as f:\n",
        "            logo_bytes = f.read()\n",
        "        logo_base64 = base64.b64encode(logo_bytes).decode('ascii')\n",
        "        logo_html = f'<img src=\"data:image/png;base64,{logo_base64}\" alt=\"TrajecPro Logo\" class=\"logo\">'\n",
        "    except FileNotFoundError:\n",
        "        logo_html = ''\n",
        "        print(\"Advertencia: 'logo.png' no encontrado. El logo no se mostrará.\")\n",
        "\n",
        "    video_and_coeff_content = f'''\n",
        "    <div class=\"left-header\">\n",
        "        <h2 class=\"main-title\">{logo_html}<span class=\"title-text\">TrajecPro</span></h2>\n",
        "    </div>\n",
        "    <div class=\"video-container\">\n",
        "        <video controls autoplay muted loop class=\"video-player\">\n",
        "            <source src=\"data:video/mp4;base64,{video_base64}\" type=\"video/mp4\">\n",
        "            Tu navegador no soporta el tag de video.\n",
        "        </video>\n",
        "        <p class=\"video-caption\">Este video muestra el objeto detectado y su centroide en cada fotograma.</p>\n",
        "    </div>\n",
        "    ''' + coeff_section_html\n",
        "else:\n",
        "    print(\"No se capturaron fotogramas para generar el video.\")\n",
        "    video_and_coeff_content = '<div class=\"error-message\">No se pudo generar el video de detección de movimiento.</div>' + coeff_section_html\n",
        "\n",
        "# ----------------- 3. INYECTAR RESULTADOS COMBINADOS AL FRONTEND CON NUEVA VISUALIZACIÓN -----------------\n",
        "\n",
        "website_style = '''\n",
        "    <style>\n",
        "        * {\n",
        "            margin: 0;\n",
        "            padding: 0;\n",
        "            box-sizing: border-box;\n",
        "        }\n",
        "\n",
        "        body {\n",
        "            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;\n",
        "            background-color: #ffffff;\n",
        "            color: #202124;\n",
        "            line-height: 1.5;\n",
        "        }\n",
        "\n",
        "        .main-container {\n",
        "            display: grid;\n",
        "            grid-template-columns: 380px 1fr;\n",
        "            max-width: 1400px;\n",
        "            margin: 0 auto;\n",
        "            background-color: #ffffff;\n",
        "            min-height: 100vh;\n",
        "        }\n",
        "\n",
        "        .left-panel {\n",
        "            background-color: #ffffff;\n",
        "            padding: 24px;\n",
        "            border-right: 1px solid #e8eaed;\n",
        "        }\n",
        "\n",
        "        .right-panel {\n",
        "            background-color: #fafafa;\n",
        "            padding: 32px 40px;\n",
        "        }\n",
        "\n",
        "        /* Left Panel Styles */\n",
        "        .left-header {\n",
        "            margin-bottom: 24px;\n",
        "        }\n",
        "\n",
        "        .main-title {\n",
        "            font-size: 24px;\n",
        "            font-weight: 400;\n",
        "            color: #202124;\n",
        "            display: flex;\n",
        "            align-items: center;\n",
        "            margin-bottom: 0;\n",
        "            border-bottom: none;\n",
        "            padding-bottom: 0;\n",
        "        }\n",
        "\n",
        "        .logo {\n",
        "            height: 28px;\n",
        "            margin-right: 12px;\n",
        "            vertical-align: middle;\n",
        "        }\n",
        "\n",
        "        .title-text {\n",
        "            font-weight: 400;\n",
        "        }\n",
        "\n",
        "        .video-container {\n",
        "            margin-bottom: 24px;\n",
        "        }\n",
        "\n",
        "        .video-player {\n",
        "            width: 100%;\n",
        "            height: auto;\n",
        "            border-radius: 8px;\n",
        "            background-color: #000;\n",
        "            display: block;\n",
        "            box-shadow: 0 1px 3px rgba(0,0,0,0.12);\n",
        "        }\n",
        "\n",
        "        .video-caption {\n",
        "            font-size: 12px;\n",
        "            color: #5f6368;\n",
        "            text-align: center;\n",
        "            margin-top: 12px;\n",
        "            line-height: 1.4;\n",
        "        }\n",
        "\n",
        "        /* Coefficient Section */\n",
        "        .coefficient-section {\n",
        "            background-color: #e8f7fc;\n",
        "            border-left: 4px solid #91f1ff;\n",
        "            padding: 16px 20px;\n",
        "            border-radius: 4px;\n",
        "            margin-top: 16px;\n",
        "        }\n",
        "\n",
        "        .coeff-title {\n",
        "            font-size: 16px;\n",
        "            font-weight: 500;\n",
        "            color: #0288d1;\n",
        "            margin-bottom: 16px;\n",
        "            border-bottom: none;\n",
        "            padding-bottom: 0;\n",
        "        }\n",
        "\n",
        "        .coeff-item {\n",
        "            margin-bottom: 12px;\n",
        "            font-size: 13px;\n",
        "            line-height: 1.6;\n",
        "        }\n",
        "\n",
        "        .coeff-item:last-child {\n",
        "            margin-bottom: 0;\n",
        "        }\n",
        "\n",
        "        .coeff-item-highlight {\n",
        "            background-color: #f3e5f5;\n",
        "            padding: 12px;\n",
        "            border-radius: 4px;\n",
        "            margin-bottom: 12px;\n",
        "            border-left: 3px solid #9956ca;\n",
        "        }\n",
        "\n",
        "        .coeff-label {\n",
        "            color: #01579b;\n",
        "            font-weight: 500;\n",
        "            display: block;\n",
        "            margin-bottom: 4px;\n",
        "        }\n",
        "\n",
        "        .coeff-value {\n",
        "            color: #0277bd;\n",
        "            font-weight: 400;\n",
        "            display: block;\n",
        "        }\n",
        "\n",
        "        .coeff-value-list {\n",
        "            color: #0277bd;\n",
        "            font-weight: 400;\n",
        "            display: block;\n",
        "            word-break: break-word;\n",
        "        }\n",
        "\n",
        "        .coeff-value-highlight {\n",
        "            color: #9956ca;\n",
        "            font-weight: 700;\n",
        "            font-size: 16px;\n",
        "            display: block;\n",
        "        }\n",
        "\n",
        "        .coeff-classification {\n",
        "            color: #1967d2;\n",
        "            font-weight: 600;\n",
        "            font-size: 15px;\n",
        "            display: block;\n",
        "        }\n",
        "\n",
        "        /* Right Panel Styles */\n",
        "        .right-panel h3 {\n",
        "            font-size: 20px;\n",
        "            font-weight: 500;\n",
        "            color: #202124;\n",
        "            margin-bottom: 24px;\n",
        "            border-bottom: none;\n",
        "            padding-bottom: 0;\n",
        "        }\n",
        "\n",
        "        .graph-container {\n",
        "            background-color: #ffffff;\n",
        "            border-radius: 8px;\n",
        "            padding: 20px;\n",
        "            margin-bottom: 24px;\n",
        "            box-shadow: 0 1px 3px rgba(0,0,0,0.08);\n",
        "        }\n",
        "\n",
        "        .graph-title {\n",
        "            font-size: 15px;\n",
        "            font-weight: 500;\n",
        "            color: #202124;\n",
        "            margin-bottom: 16px;\n",
        "            border-bottom: none;\n",
        "            padding-bottom: 0;\n",
        "        }\n",
        "\n",
        "        .graph-image {\n",
        "            width: 100%;\n",
        "            height: auto;\n",
        "            display: block;\n",
        "            border-radius: 4px;\n",
        "            cursor: pointer;\n",
        "            transition: transform 0.2s ease;\n",
        "        }\n",
        "\n",
        "        .graph-image:hover {\n",
        "            transform: scale(1.02);\n",
        "            box-shadow: 0 4px 12px rgba(0,0,0,0.15);\n",
        "        }\n",
        "\n",
        "        /* Modal para expandir imágenes */\n",
        "        .image-modal {\n",
        "            display: none;\n",
        "            position: fixed;\n",
        "            z-index: 9999;\n",
        "            left: 0;\n",
        "            top: 0;\n",
        "            width: 100%;\n",
        "            height: 100%;\n",
        "            background-color: rgba(0, 0, 0, 0.95);\n",
        "            overflow: auto;\n",
        "            animation: fadeIn 0.3s;\n",
        "        }\n",
        "\n",
        "        @keyframes fadeIn {\n",
        "            from { opacity: 0; }\n",
        "            to { opacity: 1; }\n",
        "        }\n",
        "\n",
        "        .image-modal-content {\n",
        "            display: block;\n",
        "            margin: 2% auto;\n",
        "            max-width: 95%;\n",
        "            max-height: 95%;\n",
        "            object-fit: contain;\n",
        "            animation: zoomIn 0.3s;\n",
        "        }\n",
        "\n",
        "        @keyframes zoomIn {\n",
        "            from { transform: scale(0.8); }\n",
        "            to { transform: scale(1); }\n",
        "        }\n",
        "\n",
        "        .image-modal-close {\n",
        "            position: absolute;\n",
        "            top: 20px;\n",
        "            right: 40px;\n",
        "            color: #fff;\n",
        "            font-size: 40px;\n",
        "            font-weight: bold;\n",
        "            cursor: pointer;\n",
        "            transition: 0.3s;\n",
        "            z-index: 10000;\n",
        "        }\n",
        "\n",
        "        .image-modal-close:hover,\n",
        "        .image-modal-close:focus {\n",
        "            color: #bbb;\n",
        "        }\n",
        "\n",
        "        .image-modal-caption {\n",
        "            text-align: center;\n",
        "            color: #ccc;\n",
        "            padding: 20px;\n",
        "            font-size: 18px;\n",
        "        }\n",
        "\n",
        "        .error-message {\n",
        "            background-color: #fce8e6;\n",
        "            border-left: 4px solid #d93025;\n",
        "            padding: 16px;\n",
        "            color: #c5221f;\n",
        "            font-size: 13px;\n",
        "            border-radius: 4px;\n",
        "            margin-top: 16px;\n",
        "        }\n",
        "\n",
        "        /* Responsive Design */\n",
        "        @media (max-width: 1024px) {\n",
        "            .main-container {\n",
        "                grid-template-columns: 1fr;\n",
        "            }\n",
        "\n",
        "            .left-panel {\n",
        "                border-right: none;\n",
        "                border-bottom: 1px solid #e8eaed;\n",
        "                max-width: 100%;\n",
        "            }\n",
        "\n",
        "            .right-panel {\n",
        "                padding: 24px;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        @media (max-width: 768px) {\n",
        "            .left-panel, .right-panel {\n",
        "                padding: 16px;\n",
        "            }\n",
        "\n",
        "            .main-title {\n",
        "                font-size: 20px;\n",
        "            }\n",
        "\n",
        "            .right-panel h3 {\n",
        "                font-size: 18px;\n",
        "            }\n",
        "        }\n",
        "    </style>\n",
        "'''\n",
        "\n",
        "final_combined_html = f'''\n",
        "    {website_style}\n",
        "    <!-- Modal para expandir imágenes -->\n",
        "    <div id=\"imageModal\" class=\"image-modal\">\n",
        "        <span class=\"image-modal-close\">&times;</span>\n",
        "        <img class=\"image-modal-content\" id=\"modalImage\">\n",
        "        <div class=\"image-modal-caption\" id=\"modalCaption\"></div>\n",
        "    </div>\n",
        "\n",
        "    <div class=\"main-container\">\n",
        "        <div class=\"left-panel\">\n",
        "            {video_and_coeff_content}\n",
        "        </div>\n",
        "        <div class=\"right-panel\">\n",
        "            <h3>Análisis de Resultados de Trayectoria y Posición</h3>\n",
        "            {right_panel_content}\n",
        "        </div>\n",
        "    </div>\n",
        "\n",
        "    <script>\n",
        "        // Funcionalidad del modal para expandir imágenes\n",
        "        document.addEventListener('DOMContentLoaded', function() {{\n",
        "            const modal = document.getElementById('imageModal');\n",
        "            const modalImg = document.getElementById('modalImage');\n",
        "            const modalCaption = document.getElementById('modalCaption');\n",
        "            const closeBtn = document.querySelector('.image-modal-close');\n",
        "\n",
        "            // Agregar evento click a todas las imágenes expandibles\n",
        "            const expandableImages = document.querySelectorAll('.expandable-image');\n",
        "            expandableImages.forEach(function(img) {{\n",
        "                img.addEventListener('click', function() {{\n",
        "                    modal.style.display = 'block';\n",
        "                    modalImg.src = this.src;\n",
        "                    const title = this.closest('.graph-container').querySelector('.graph-title');\n",
        "                    modalCaption.textContent = title ? title.textContent : '';\n",
        "                }});\n",
        "            }});\n",
        "\n",
        "            // Cerrar modal al hacer clic en X\n",
        "            closeBtn.addEventListener('click', function() {{\n",
        "                modal.style.display = 'none';\n",
        "            }});\n",
        "\n",
        "            // Cerrar modal al hacer clic fuera de la imagen\n",
        "            modal.addEventListener('click', function(e) {{\n",
        "                if (e.target === modal) {{\n",
        "                    modal.style.display = 'none';\n",
        "                }}\n",
        "            }});\n",
        "\n",
        "            // Cerrar modal con tecla ESC\n",
        "            document.addEventListener('keydown', function(e) {{\n",
        "                if (e.key === 'Escape' && modal.style.display === 'block') {{\n",
        "                    modal.style.display = 'none';\n",
        "                }}\n",
        "            }});\n",
        "        }});\n",
        "    </script>\n",
        "'''\n",
        "\n",
        "final_display_js_combined = f'''\n",
        "    var results_area = document.getElementById('results_area');\n",
        "    if (results_area) {{\n",
        "        results_area.innerHTML = `{final_combined_html.replace(\"`\", \"\\\\`\")}`;\n",
        "        var parent_div = results_area.closest('div[style]');\n",
        "        if (parent_div) {{\n",
        "            parent_div.removeAttribute('style');\n",
        "        }}\n",
        "    }}\n",
        "'''\n",
        "\n",
        "eval_js(final_display_js_combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X_sCGbhLKp3a",
        "outputId": "7ece0185-4058-47a3-e513-84cb30ebaebf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"font-family: sans-serif; padding: 10px; border: 1px solid #ccc; border-radius: 8px; width: 680px; margin: auto;\">\n",
              "        <h2 style=\"margin-top: 0;\"> Detector de Movimiento</h2>\n",
              "        <p>Haz clic en el video para detener la captura y guardar el CSV.</p>\n",
              "\n",
              "        <div id=\"video_container\" style=\"position: relative; width: 640px; height: 480px; margin: auto; border: 2px solid black;\">\n",
              "            <video id=\"video_element\" style=\"display: block; width: 100%; height: 100%;\" autoplay playsinline></video>\n",
              "            <img id=\"overlay_element\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1;\">\n",
              "        </div>\n",
              "\n",
              "        <div style=\"margin-top: 10px; font-size: 1.1em;\">\n",
              "            <strong>Estado:</strong> <span id=\"status_label\" style=\"font-weight: bold; color: #555;\">Iniciando...</span>\n",
              "        </div>\n",
              "\n",
              "        <div id=\"results_area\" style=\"margin-top: 20px; text-align: center;\">\n",
              "            <p>Esperando la finalización del video para generar el análisis...</p>\n",
              "        </div>\n",
              "    </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var overlay;\n",
              "    var captureCanvas;\n",
              "    var labelElement;\n",
              "    var stream;\n",
              "\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "\n",
              "    function removeDom() {\n",
              "       if (stream) {\n",
              "           stream.getVideoTracks()[0].stop();\n",
              "       }\n",
              "       video = null;\n",
              "       overlay = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "       stream = null;\n",
              "    }\n",
              "\n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8);\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function createDom() {\n",
              "      if (video) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      // Encontrar los elementos que definimos en el HTML\n",
              "      video = document.getElementById('video_element');\n",
              "      overlay = document.getElementById('overlay_element');\n",
              "      labelElement = document.getElementById('status_label');\n",
              "\n",
              "      // Configurar el canvas oculto para la captura\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640;\n",
              "      captureCanvas.height = 480;\n",
              "\n",
              "      // Iniciar la cámara\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\" }});\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Configurar el clic para detener\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      overlay.onclick = () => { shutdown = true; };\n",
              "\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      return stream;\n",
              "    }\n",
              "\n",
              "    // Esta es la función que Python llama (el \"puente\")\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "\n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "\n",
              "      if (imgData != \"\") {\n",
              "        overlay.src = imgData;\n",
              "      }\n",
              "\n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "\n",
              "      return {'create': preShow - preCreate,\n",
              "              'show': preCapture - preShow,\n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando stream... Haz clic en el video para detener y generar el análisis.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2186210051.py:27: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
            "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stream detenido. Se procesaron 82 fotogramas.\n",
            "Datos guardados exitosamente en 'centroid_data.csv'\n",
            "Video 'motion_detection_video.mp4' generado exitosamente con 82 fotogramas.\n",
            "Advertencia: 'logo.png' no encontrado. El logo no se mostrará.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- 4. CREAR SERVIDOR WEB Y LINK PÚBLICO -----------------\n",
        "\n",
        "# Guardar el HTML completo en un archivo\n",
        "html_output_file = 'trajecpro_results.html'\n",
        "with open(html_output_file, 'w', encoding='utf-8') as f:\n",
        "    f.write(f'''\n",
        "    <!DOCTYPE html>\n",
        "    <html lang=\"es\">\n",
        "    <head>\n",
        "        <meta charset=\"UTF-8\">\n",
        "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "        <title>TrajecPro - Análisis de Trayectoria</title>\n",
        "    </head>\n",
        "    <body>\n",
        "        {final_combined_html}\n",
        "    </body>\n",
        "    </html>\n",
        "    ''')\n",
        "\n",
        "print(f\"\\n Archivo HTML guardado: {html_output_file}\")\n",
        "\n",
        "# Importar Flask (corrección del error)\n",
        "from flask import Flask, render_template_string\n",
        "from threading import Thread\n",
        "import time as time_module\n",
        "\n",
        "# Crear aplicación Flask\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    with open(html_output_file, 'r', encoding='utf-8') as f:\n",
        "        html_content = f.read()\n",
        "    return html_content\n",
        "\n",
        "def run_flask():\n",
        "    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n",
        "\n",
        "# Iniciar servidor Flask en un hilo separado\n",
        "flask_thread = Thread(target=run_flask, daemon=True)\n",
        "flask_thread.start()\n",
        "\n",
        "print(\"\\n Iniciando servidor Flask...\")\n",
        "time_module.sleep(3)  # Dar tiempo para que Flask inicie\n",
        "\n",
        "# Instalar e iniciar ngrok\n",
        "print(\"\\n Instalando ngrok...\")\n",
        "get_ipython().system('pip install -q pyngrok')\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# --- IMPORTANTE: Configura tu token de autenticación de ngrok aquí ---\n",
        "# Si ya tienes una cuenta de ngrok, obtén tu token desde https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "# y reemplaza \"TU_AUTHTOKEN_AQUI\" con tu token real.\n",
        "\n",
        "# ngrok.set_auth_token(\"TU_AUTHTOKEN_AQUI\")\n",
        "# Descomenta la línea de arriba y pega tu token si tienes uno.\n",
        "\n",
        "# Crear túnel público\n",
        "print(\"\\n Creando túnel público con ngrok...\")\n",
        "public_url = ngrok.connect(5000, bind_tls=True)\n",
        "ngrok_url = public_url.public_url\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" ¡LISTO! Tu análisis está disponible públicamente:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n Link público: {ngrok_url}\")\n",
        "print(f\"\\n Comparte este link para ver los resultados desde cualquier dispositivo\")\n",
        "print(\"\\n  Nota: El link estará activo mientras este notebook esté ejecutándose\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Mantener el servidor activo\n",
        "print(\"\\n Servidor activo. Presiona el botón 'Stop' para detener.\")\n",
        "print(\" El link seguirá funcionando hasta que detengas esta celda.\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd5Dr-N0A2_-",
        "outputId": "d0ab3b35-171a-440d-dc38-c7463f679a96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Archivo HTML guardado: trajecpro_results.html\n",
            "\n",
            " Iniciando servidor Flask...\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Instalando ngrok...\n",
            "\n",
            " Creando túnel público con ngrok...\n",
            "\n",
            "============================================================\n",
            " ¡LISTO! Tu análisis está disponible públicamente:\n",
            "============================================================\n",
            "\n",
            " Link público: https://kai-unwhimpering-unseeingly.ngrok-free.dev\n",
            "\n",
            " Comparte este link para ver los resultados desde cualquier dispositivo\n",
            "\n",
            "  Nota: El link estará activo mientras este notebook esté ejecutándose\n",
            "============================================================\n",
            "\n",
            " Servidor activo. Presiona el botón 'Stop' para detener.\n",
            " El link seguirá funcionando hasta que detengas esta celda.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import os\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# 1. Kill all ngrok tunnels first\n",
        "try:\n",
        "    ngrok.kill()\n",
        "    print(\" Ngrok processes killed.\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# 2. Function to find and kill processes on specific ports\n",
        "def kill_port(port):\n",
        "    try:\n",
        "        # 'fuser -k' finds the process using the port and kills it\n",
        "        result = os.system(f\"fuser -k {port}/tcp\")\n",
        "        if result == 0:\n",
        "            print(f\" Process on port {port} killed successfully.\")\n",
        "        else:\n",
        "            print(f\"ℹ No process found on port {port} (or failed to kill).\")\n",
        "\n",
        "        # Fail-safe: Try using lsof just in case fuser didn't catch it\n",
        "        os.system(f\"lsof -t -i:{port} | xargs kill -9 2>/dev/null\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error cleaning port {port}: {e}\")\n",
        "\n",
        "# 3. Kill the common ports we've been using\n",
        "kill_port(5000)  # Default Flask port\n",
        "kill_port(5050)  # The port used in the V5 code\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "Cu8R0aFy9sVc",
        "outputId": "eb6db9ba-e170-4148-d5f2-4b418b7d9d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport os\\nfrom pyngrok import ngrok\\n\\n# 1. Kill all ngrok tunnels first\\ntry:\\n    ngrok.kill()\\n    print(\"✅ Ngrok processes killed.\")\\nexcept:\\n    pass\\n\\n# 2. Function to find and kill processes on specific ports\\ndef kill_port(port):\\n    try:\\n        # \\'fuser -k\\' finds the process using the port and kills it\\n        result = os.system(f\"fuser -k {port}/tcp\")\\n        if result == 0:\\n            print(f\"✅ Process on port {port} killed successfully.\")\\n        else:\\n            print(f\"ℹ️ No process found on port {port} (or failed to kill).\")\\n            \\n        # Fail-safe: Try using lsof just in case fuser didn\\'t catch it\\n        os.system(f\"lsof -t -i:{port} | xargs kill -9 2>/dev/null\")\\n    except Exception as e:\\n        print(f\"Error cleaning port {port}: {e}\")\\n\\n# 3. Kill the common ports we\\'ve been using\\nkill_port(5000)  # Default Flask port\\nkill_port(5050)  # The port used in the V5 code\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CZZ1kwWk91Pk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}